{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Slovene preprocessing, rule-based systems, regular expressions\n",
    "\n",
    "<sup>This notebook is a part of Natural Language Processing class at the University of Ljubljana, Faculty for computer and information science. Please contact [slavko.zitnik@fri.uni-lj.si](mailto:slavko.zitnik@fri.uni-lj.si) for any comments.</sub>\n",
    "\n",
    "## Slovene preprocessing\n",
    "\n",
    "Most of the tools and corpora is available at [ssj.slovenscina.eu](http://ssj.slovenscina.eu/) or [clarin.si](http://www.clarin.si/info/o-projektu/). Some direct links to the available tools are:\n",
    "\n",
    "* [Part-of-speech tagger](http://oznacevalnik.slovenscina.eu/Vsebine/Sl/ProgramskaOprema/Navodila.aspx): The  tool includes part-of-speech pagger, tokenizer and lemmatizer Lemmagen. Part-of-speech annotation examples are described at [http://bos.zrc-sazu.si/bibliografija/o_oznake.html](http://bos.zrc-sazu.si/bibliografija/o_oznake.html), [http://nl.ijs.si/imp/msd/html-sl/](http://nl.ijs.si/imp/msd/html-sl/) or [https://www.jakopin.net/primoz/disertacija/oblikozn.php](https://www.jakopin.net/primoz/disertacija/oblikozn.php).\n",
    "* [Dependency parser](http://razclenjevalnik.slovenscina.eu/Default.aspx) - Labels explanation [\"Površinskoskladenjsko označevanje korpusa Slovene Dependency Treebank,\" bachelor thesis by Nina Ledinek](https://nl.ijs.si/sdt/bib/SDT-diploma-nina.pdf).\n",
    "* [Lemmatizer Lemmagen](http://lemmatise.ijs.si/Software/): A port to Java also exists - [Lemmagen4J](https://github.com/szitnik/Lemmagen4J)\n",
    "* Currently best lemmatizer, tokenizer, part-of-speech tagger (year 2021) is based on Stanford's model and available at [clarin repository](https://www.clarin.si/repository/xmlui/handle/11356/1412).\n",
    "\n",
    "There already exist some pre-trained deep neural network model we will discuss later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rule-based systems\n",
    "\n",
    "Rule-based systems use manually defined set of rules to extract structured data. The extraction workflow generally consists of the following steps (*Rule-Based Information Extraction for Structured Data Acquisition using TEXTMARKER* (2008), Martin Atzmueller et al.):\n",
    "\n",
    "<img src=\"rule-based-system.png\" />\n",
    "\n",
    "The use of statistical models or deep learning networks for structured data extraction is increasing, although commetcial systems still heavily rely on manual extraction rules. Pleae read the IBM paper *Rule-based Information Extraction is Dead! Long Live Rule-based Information Extraction Systems!* (2013) by Laura Chiticariu et al..\n",
    "\n",
    "### GATE\n",
    "\n",
    "[GATE](https://gate.ac.uk/) is a natural language processing framework that consists of a GUI application, a set of extensible tools and a Java library to develop custom extensions. \n",
    "\n",
    "It includes a rule-based information extraction system called [ANNIE](https://gate.ac.uk/sale/tao/splitch6.html#x9-1200006) that heavily relies on [JAPE](https://gate.ac.uk/sale/tao/splitch8.html#x12-2070008) (Java Annotations Patterns Engine) rules.\n",
    "\n",
    "<img src=\"gate-developer.png\" />\n",
    "\n",
    "\n",
    "### UIMA\n",
    "\n",
    "[Apache UIMA](https://uima.apache.org) is another framework for information extraction. Apart from open-source plugins, some commercialized versions exist. The framework became especially known after the IBM Watson's win at the [Jeopardy challenge](https://www.youtube.com/watch?v=WFR3lOm_xhE) because Watson engine was based on UIMA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regular expressions\n",
    "\n",
    "One of the standardized ways to extract structured information from text is the use of regular expressions. To get familiar with the regular expressions, follow a tutorial at [RegexOne](https://regexone.com/) or go through explanations at [Regular-Expressions.info](http://www.regular-expressions.info/). \n",
    "\n",
    "While you learn and also when you want to test some regular expression examples against some text, you can help yourself using tools such as [Regex101](https://regex101.com/).\n",
    "\n",
    "### Regular expressions in Python\n",
    "Let's try some regular expressions in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"Mr. Swensen, 62, runs the school’s $25.4 billion endowment, one of the largest in the country. \n",
    "Since November 1 2016 he is joined by his intellectual sparring partner, Mr. Dean Takahashi, his senior director.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found person: 'Swensen'.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "regex = \"Mr. (\\w+)\"\n",
    "\n",
    "# Find person\n",
    "personPattern = re.compile(regex)\n",
    "match = personPattern.search(text)\n",
    "print(\"Found person: '{}'.\".format( match.group(1) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found person: 'Swensen'.\n",
      "Found person: 'Dean'.\n"
     ]
    }
   ],
   "source": [
    "# Find all persons\n",
    "matches = re.finditer(regex, text)\n",
    "for match in matches:\n",
    "    print(\"Found person: '{}'.\".format( match.group(1) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount: '$25.4'.\n"
     ]
    }
   ],
   "source": [
    "# Find money amounts\n",
    "regex = \"[$€]\\s*[0-9\\.,]+\"\n",
    "matches = re.finditer(regex, text)\n",
    "for match in matches:\n",
    "    print(\"Amount: '{}'.\".format( match.group(0) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: write a general regex for dates while identifying month, day and year separately"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "#### GATE and JAPE rules\n",
    "\n",
    "Install GATE Developer, try to use ANNIE against some english news text, investigate JAPE rules (some predefined ones are listed [here](https://gate.ac.uk/sale/tao/splitap6.html#x38-773000F)). Try to define some new JAPE rules.\n",
    "\n",
    "#### NLTK regular expressions\n",
    "\n",
    "To check some simple examples using Python and NLTK, please read *Regular Expressions for Natural Language Processing* (2006) by Steven Bird and Ewan Klein. Solve the exercises at the end of the document.\n",
    "\n",
    "#### CMU Seminars\n",
    "\n",
    "1. Download the [CMU Seminar Announcements](https://people.cs.umass.edu/~mccallum/data/sa-tagged.tar.gz) dataset.\n",
    "2. Remove all XML tags from texts.\n",
    "3. Use regular expressions to recognize parts of the announcements. Which parts can you recognize (date, time, location, names, emails)?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nlp-course-fri-2]",
   "language": "python",
   "name": "conda-env-nlp-course-fri-2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
